{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os    \n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from model import EfficientNet_B0\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cifar-10-batches-py', 'cifar-10-python.tar.gz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch = 256\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_cifar(classifier, optimizer, scheduler, trainloader, testloader, name, epochs=100, print_freq=1, device=None):\n",
    "    # save model\n",
    "    best_epoch = 0\n",
    "    best_loss = 999\n",
    "    best_weights = copy.deepcopy(classifier.state_dict())\n",
    "    \n",
    "    save_dir = 'saved_models/' + name + '/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        #training\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()*len(inputs)\n",
    "        running_loss = running_loss/50000\n",
    "        \n",
    "        #testing\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        for data in testloader:\n",
    "            with torch.no_grad():\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = classifier(images)\n",
    "                test_loss += loss.item()*len(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        test_loss = test_loss/10000\n",
    "        \n",
    "        train_losses.append(running_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_acc.append(correct/total)\n",
    "        #test every 'print_freq' epochs\n",
    "        if epoch % print_freq == 0:\n",
    "            print(f'epoch: {epoch+1}/{epochs}, train loss: {train_losses[-1]:.4f}, test loss: {test_losses[-1]:.4f}, test acc: {correct/total:.4f}')\n",
    "    \n",
    "     \n",
    "        if best_loss < test_loss:\n",
    "            best_loss = test_loss\n",
    "            best_weights = copy.deepcopy(classifier.state_dict())\n",
    "        # update scheduler\n",
    "#         scheduler.step()\n",
    "        \n",
    "    torch.save(best_weights, os.path.join(save_dir, 'best.pth'))\n",
    "    print('best epoch: {}'.format(best_epoch))\n",
    "    \n",
    "    classifier.load_state_dict(best_weights)\n",
    "    \n",
    "    return train_losses, test_losses, test_acc, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(train_losses,test_losses,test_acc,saveto):\n",
    "    # Plot the loss function and train / validation accuracies\n",
    "    plt.figure(figsize=(8,10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_losses,label='train')\n",
    "    plt.plot(test_losses,label='test')\n",
    "    plt.title('Loss history')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(test_acc, label='train')\n",
    "    plt.title('Classification accuracy history')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Classification accuracy')\n",
    "    plt.show()\n",
    "    plt.savefig(saveto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, train loss: 2.4785, test loss: 2.0363, test acc: 0.2613\n",
      "epoch: 2/100, train loss: 1.8747, test loss: 1.7352, test acc: 0.3668\n",
      "epoch: 3/100, train loss: 1.6536, test loss: 1.5921, test acc: 0.4086\n",
      "epoch: 4/100, train loss: 1.5323, test loss: 1.5138, test acc: 0.4443\n",
      "epoch: 5/100, train loss: 1.4485, test loss: 1.4703, test acc: 0.4615\n",
      "epoch: 6/100, train loss: 1.3842, test loss: 1.4246, test acc: 0.4741\n",
      "epoch: 7/100, train loss: 1.3285, test loss: 1.3910, test acc: 0.4910\n",
      "epoch: 8/100, train loss: 1.2821, test loss: 1.3655, test acc: 0.5035\n",
      "epoch: 9/100, train loss: 1.2363, test loss: 1.3532, test acc: 0.5091\n",
      "epoch: 10/100, train loss: 1.1940, test loss: 1.3466, test acc: 0.5196\n",
      "epoch: 11/100, train loss: 1.1487, test loss: 1.3217, test acc: 0.5235\n",
      "epoch: 12/100, train loss: 1.1116, test loss: 1.3278, test acc: 0.5248\n",
      "epoch: 13/100, train loss: 1.0801, test loss: 1.3143, test acc: 0.5345\n",
      "epoch: 14/100, train loss: 1.0379, test loss: 1.3286, test acc: 0.5301\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classifier = EfficientNet_B0().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
    "train_losses, test_losses, test_acc, classifier = train_cifar(classifier, optimizer, scheduler, trainloader, testloader,\n",
    "                                                    'EfficientNet-B0', epochs=100, print_freq=1)\n",
    "\n",
    "plot_history(train_losses, test_losses, test_acc, saveto='../save_plot/EfficientNet-B0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = models.resnet18(pretrained=False)\n",
    "classifier.fc = nn.Linear(512, len(classes))\n",
    "classifier.to(device)\n",
    "\n",
    "train_losses, test_losses, test_acc, classifier = train_cifar(classifier, optimizer, scheduler, trainloader, testloader,\n",
    "                                                   'ResNet-18', epochs=10, print_freq=1)\n",
    "\n",
    "plot_history(train_losses, test_losses, test_acc, saveto='../save_plot/ResNet-18.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
